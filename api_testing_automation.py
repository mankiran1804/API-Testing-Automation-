# -*- coding: utf-8 -*-
"""API Testing Automation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N_EUcxbgba-ZBW_1LQ41jGwGbpNjfG6R
"""

import requests
import pandas as pd
import time
import asyncio
import aiohttp
import nest_asyncio
import json
from jsonschema import validate, ValidationError
from jinja2 import Template
from IPython.display import display, IFrame

nest_asyncio.apply()

# ------------------ CONFIG ------------------

API_ENDPOINTS = [
    {"name": "Get Products", "method": "GET", "url": "https://fakestoreapi.com/products"},
    {"name": "Get Single Product", "method": "GET", "url": "https://fakestoreapi.com/products/1"},
    {"name": "Invalid Endpoint", "method": "GET", "url": "https://fakestoreapi.com/invalid"},
]

CONCURRENT_USERS = 20  # For performance test

# ------------------ SCHEMA ------------------

product_schema = {
    "type": "object",
    "properties": {
        "id": {"type": "number"},
        "title": {"type": "string"},
        "price": {"type": "number"},
        "description": {"type": "string"},
        "category": {"type": "string"},
        "image": {"type": "string"},
    },
    "required": ["id", "title", "price"]
}

# ------------------ VALIDATION FUNCTIONS ------------------

def validate_schema(data, schema):
    try:
        validate(instance=data, schema=schema)
        return True
    except ValidationError:
        return False

# ------------------ FUNCTIONAL TEST ------------------

def run_functional_tests_enhanced():
    results = []
    for api in API_ENDPOINTS:
        name = api['name']
        url = api['url']
        method = api['method']
        try:
            print(f"Testing: {name}")
            start = time.time()
            response = requests.request(method, url)
            duration = round((time.time() - start) * 1000, 2)

            try:
                json_data = response.json()
                is_json = True
                schema_valid = validate_schema(json_data, product_schema) if "Single" in name else "N/A"
            except:
                is_json = False
                schema_valid = False

            results.append({
                "API Name": name,
                "Method": method,
                "URL": url,
                "Status Code": response.status_code,
                "JSON Valid": is_json,
                "Schema Valid": schema_valid,
                "Response Time (ms)": duration,
                "Result": "PASS" if response.status_code == 200 and is_json else "FAIL"
            })
        except Exception as e:
            results.append({
                "API Name": name,
                "Method": method,
                "URL": url,
                "Status Code": "Error",
                "JSON Valid": False,
                "Schema Valid": False,
                "Response Time (ms)": "N/A",
                "Result": "FAIL",
                "Error": str(e)
            })
    return pd.DataFrame(results)

# ------------------ PERFORMANCE TEST ------------------

async def async_test(session, url):
    try:
        start = time.time()
        async with session.get(url) as response:
            await response.text()
            duration = round((time.time() - start) * 1000, 2)
            return duration
    except:
        return None

async def run_performance_test(url, users):
    async with aiohttp.ClientSession() as session:
        tasks = [async_test(session, url) for _ in range(users)]
        durations = await asyncio.gather(*tasks)
        durations = [d for d in durations if d is not None]
        return {
            "Total Requests": users,
            "Successful": len(durations),
            "Avg Time (ms)": round(sum(durations) / len(durations), 2) if durations else None,
            "Min Time (ms)": min(durations) if durations else None,
            "Max Time (ms)": max(durations) if durations else None
        }

# ------------------ HTML REPORT ------------------

def generate_html_report(df_func, df_perf, file_path="api_test_report.html"):
    html_template = """
    <html>
    <head>
        <title>API Test Report</title>
        <style>
            body { font-family: Arial; }
            h2 { color: #2F4F4F; }
            table { border-collapse: collapse; width: 100%; margin-bottom: 40px;}
            th, td { border: 1px solid #ccc; padding: 8px; text-align: center; }
            th { background-color: #f2f2f2; }
            .pass { background-color: #d4edda; }
            .fail { background-color: #f8d7da; }
        </style>
    </head>
    <body>
        <h2>Functional Test Results</h2>
        {{ func_table }}
        <h2>Performance Test Results</h2>
        {{ perf_table }}
    </body>
    </html>
    """
    template = Template(html_template)

    func_html = df_func.to_html(classes="func", index=False)
    perf_html = df_perf.to_html(classes="perf", index=False)

    html_out = template.render(func_table=func_html, perf_table=perf_html)

    with open(file_path, "w") as f:
        f.write(html_out)

    print(f"HTML Report generated: {file_path}")

# ------------------ COMBINED RUNNER ------------------

def run_combined_tests():
    print("Running Functional Tests...\n")
    func_results = run_functional_tests_enhanced()
    display(func_results)
    func_results.to_csv("functional_test_report.csv", index=False)

    print("\nRunning Performance Test (Simulated Load)...\n")
    perf_results = []

    for api in API_ENDPOINTS:
        if api["method"] == "GET":
            print(f"Load Testing: {api['name']} ({CONCURRENT_USERS} users)")
            perf_result = asyncio.run(run_performance_test(api["url"], CONCURRENT_USERS))
            perf_result["API Name"] = api["name"]
            perf_result["URL"] = api["url"]
            perf_results.append(perf_result)

    df_perf = pd.DataFrame(perf_results)
    display(df_perf)
    df_perf.to_csv("performance_test_report.csv", index=False)

    generate_html_report(func_results, df_perf)
    display(IFrame(src='api_test_report.html', width='100%', height='500px'))

# ------------------ RUN ------------------

run_combined_tests()